{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2e804e5-0980-4cb8-891c-59d581a20e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4153ad1-9d17-444b-93b6-f5f8204abacb",
   "metadata": {},
   "source": [
    "# Torch型別轉換\n",
    "## Torch & Numpy & list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a3bc140-d467-448b-8f40-dc3901a0c5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_data:\n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]], dtype=torch.int32) <class 'torch.Tensor'>\n",
      "\n",
      "tensor2array:\n",
      " [[0 1 2]\n",
      " [3 4 5]] <class 'numpy.ndarray'>\n",
      "array2list:\n",
      " [[0, 1, 2], [3, 4, 5]] <class 'list'>\n",
      "tensor_gpu_requires_grad2array:\n",
      " [[0 1 2]\n",
      " [3 4 5]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_data = np.arange(6).reshape((2, 3))\n",
    "torch_data = torch.from_numpy(np_data)  \n",
    "tensor2array = torch_data.numpy()\n",
    "array2list =  np_data.tolist()\n",
    "# 轉Numpy時必須確保是 在cpu上運算 且 requires_grad=False\n",
    "# .detach(): requires_grad變為False\n",
    "tensor_gpu_requires_grad2array= torch_data.cpu().detach().numpy()  \n",
    "print('torch_data:\\n', torch_data, type(torch_data))\n",
    "print('\\ntensor2array:\\n', tensor2array, type(tensor2array))\n",
    "print('array2list:\\n', array2list, type(array2list))\n",
    "print('tensor_gpu_requires_grad2array:\\n', tensor_gpu_requires_grad2array, type(tensor_gpu_requires_grad2array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c12b2e-ebb9-4729-b523-7ebf94ba4a97",
   "metadata": {},
   "source": [
    "## 簡單運算(和Numpy類似)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43872184-966c-4308-ab57-51658aa99b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_int64:\n",
      " tensor([-1, -2,  1,  2]) torch.int64\n",
      "tensor_float32:\n",
      " tensor([-1., -2.,  1.,  2.]) torch.float32\n",
      "\n",
      "abs \n",
      "numpy:  [1 2 1 2] \n",
      "torch:  tensor([1., 2., 1., 2.])\n",
      "\n",
      "sin \n",
      "numpy:  [-0.84147098 -0.90929743  0.84147098  0.90929743] \n",
      "torch:  tensor([-0.8415, -0.9093,  0.8415,  0.9093])\n",
      "\n",
      "mean \n",
      "numpy:  0.0 \n",
      "torch:  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# abs 绝对值计算\n",
    "data = [-1, -2, 1, 2]\n",
    "tensor_int64 = torch.tensor(data)\n",
    "print('tensor_int64:\\n', tensor_int64, tensor_int64.dtype)\n",
    "tensor_float32 = tensor_int64.type(torch.FloatTensor)  # .type()做 dtype的變換\n",
    "print('tensor_float32:\\n', tensor_float32, tensor_float32.dtype)\n",
    "# tensor = torch.FloatTensor(data)  # 直接創建\n",
    "print(\n",
    "    '\\nabs',\n",
    "    '\\nnumpy: ', np.abs(data),          # [1 2 1 2]\n",
    "    '\\ntorch: ', torch.abs(tensor_float32)      # [1 2 1 2]\n",
    ")\n",
    "\n",
    "# sin   三角函数 sin\n",
    "print(\n",
    "    '\\nsin',\n",
    "    '\\nnumpy: ', np.sin(data),      # [-0.84147098 -0.90929743  0.84147098  0.90929743]\n",
    "    '\\ntorch: ', torch.sin(tensor_float32)  # [-0.8415 -0.9093  0.8415  0.9093]\n",
    ")\n",
    "\n",
    "# mean  均值\n",
    "print(\n",
    "    '\\nmean',\n",
    "    '\\nnumpy: ', np.mean(data),         # 0.0\n",
    "    '\\ntorch: ', torch.mean(tensor_float32)     # 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52fe0b3-3b1a-44e2-9987-8baa98b5b6d4",
   "metadata": {},
   "source": [
    "# transforms\n",
    "## transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c944346a-8a4c-463d-8208-c40e55c57ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(img_PIL2tensor):  <class 'torch.Tensor'>\n",
      "type(img_PIL2tensor):  <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "img_path = './Data/hymenoptera_data/train/0/0013035.jpg'\n",
    "img_PIL = Image.open(img_path)\n",
    "img_CV2 = cv2.imread(img_path)\n",
    "\n",
    "# 創建一個ToTensor這個class的物件 \n",
    "tensor_trans = transforms.ToTensor()  \n",
    "# 調用ToTensor這個class的 __call__方法, 轉為tensor, 可傳入PIL Image or np.array\n",
    "img_PIL2tensor = tensor_trans(img_PIL)        \n",
    "img_CV22tensor = tensor_trans(img_CV2)\n",
    "print('type(img_PIL2tensor): ', type(img_PIL2tensor))\n",
    "print('type(img_PIL2tensor): ', type(img_PIL2tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d7e16-1c8e-4708-8b97-d636da5c9784",
   "metadata": {},
   "source": [
    "## transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99700ed7-5f2d-4f54-85b2-90f063a0eb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_trans = transforms.ToPILImage()\n",
    "img_PIL = tensor_trans(img_PIL2tensor)  # 可傳入PIL Image or np.array\n",
    "type(img_PIL)\n",
    "# img_PIL.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b44cab-f1cf-4e35-8d47-ab81097cc9c6",
   "metadata": {},
   "source": [
    "## transforms.Normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9dd5744-a90c-41c0-b98c-038f4adb9af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3137)\n",
      "tensor(-0.3725)\n",
      "-0.37260000000000004\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "# output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "image_path = './Data/hymenoptera_data/train/0/0013035.jpg'\n",
    "img = Image.open(image_path)\n",
    "trans_toTensor = transforms.ToTensor()\n",
    "img_tensor = trans_toTensor(img)\n",
    "print(img_tensor[0][0][0])\n",
    "# 均值, 標準差, 僅能輸入tensor類型\n",
    "trans_norm = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # RGB\n",
    "img_norm = trans_norm(img_tensor)\n",
    "print(img_norm[0][0][0])  # out = (input - mean)/ std\n",
    "print((0.3137 - 0.5) / 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c55362-a1f6-445c-b8db-f65d781dc8f3",
   "metadata": {},
   "source": [
    "## transforms.Resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3b657c5-0643-46a9-aa21-87de402742d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "<class 'PIL.Image.Image'>\n",
      "torch.Size([3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Resize\n",
    "image_path = './Data/hymenoptera_data/train/0/0013035.jpg'\n",
    "img = Image.open(image_path)\n",
    "print(type(img))\n",
    "# Resize the input image to the given size.\n",
    "#     If the image is torch Tensor, it is expected\n",
    "#     to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions\n",
    "# 只改長寬, 只改[..., H, W], 所以輸入為(h, w) 2維\n",
    "trans_resize = transforms.Resize((128, 128))  # 僅能傳去PIL Image\n",
    "img_PIL_resize = trans_resize(img)\n",
    "print(type(img_PIL_resize))  # PIL Image\n",
    "trans_toTensor = transforms.ToTensor()\n",
    "img_tensor_resize = trans_toTensor(img_PIL_resize)\n",
    "print(img_tensor_resize.shape)\n",
    "\n",
    "# # 可視化\n",
    "# trans = transforms.ToPILImage()\n",
    "# img = trans(img_tensor_resize)\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dccecc-8c03-488f-9def-4361b3812c70",
   "metadata": {},
   "source": [
    "## transforms.Compose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d18ca06c-936b-4746-9493-266800343784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 512)\n",
      "torch.Size([3, 224, 336])\n"
     ]
    }
   ],
   "source": [
    "# Compose, Resize ---2\n",
    "image_path = './Data/hymenoptera_data/train/0/0013035.jpg'\n",
    "img = Image.open(image_path)\n",
    "print(img.size)\n",
    "trans_toTensor = transforms.ToTensor()\n",
    "trans_resize2 = transforms.Resize(224)  # 僅傳入一個數值就等比縮放\n",
    "# 把所有轉換存在一起的概念, 依序執行\n",
    "trans_Compose = transforms.Compose([\n",
    "    trans_resize2,\n",
    "    trans_toTensor\n",
    "])\n",
    "img_resize2 = trans_Compose(img)\n",
    "print(img_resize2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b062dc-7568-414b-aee2-5b680910c650",
   "metadata": {},
   "source": [
    "## transforms.RandomCrop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89249546-3e9c-4615-ae5f-5fdc680cea7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 512)\n",
      "torch.Size([3, 224, 100])\n"
     ]
    }
   ],
   "source": [
    "# Compose, Resize ---2\n",
    "image_path = './Data/hymenoptera_data/train/0/0013035.jpg'\n",
    "img = Image.open(image_path)\n",
    "img.show()\n",
    "print(img.size)\n",
    "# 指定大小, 隨機裁剪出該大小的圖片\n",
    "trans_random = transforms.RandomCrop((224, 100))  \n",
    "# 把所有轉換存在一起的概念, 依序執行\n",
    "trans_Compose = transforms.Compose([\n",
    "    trans_random,\n",
    "    trans_toTensor\n",
    "])\n",
    "img_resize2 = trans_Compose(img)\n",
    "print(img_resize2.shape)\n",
    "# # 可視化\n",
    "trans = transforms.ToPILImage()\n",
    "img = trans(img_resize2)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed573b-6522-4fd7-ac37-93dee61ce952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
