{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b2e96b-32db-408b-a6f3-915c50e79a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f189eea2-0126-497f-a118-0b9ed086306b",
   "metadata": {},
   "source": [
    "# 數據集加載\n",
    "## Dataset\n",
    "### 抽象類別, 所有的數據集都必須繼承Dataset並且重寫 \"__getitem__\" 和 \"__len__\" 方法\n",
    "### \"__getitem__\": 獲取每個數據對應的label\n",
    "###  \"__len__\": 數據總數\n",
    "## Dataset相關文檔查閱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedefaed-7a16-4dd2-87dd-f03cc527fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dataset in module torch.utils.data.dataset:\n",
      "\n",
      "class Dataset(typing.Generic)\n",
      " |  An abstract class representing a :class:`Dataset`.\n",
      " |  \n",
      " |  All datasets that represent a map from keys to data samples should subclass\n",
      " |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      " |  data sample for a given key. Subclasses could also optionally overwrite\n",
      " |  :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      " |  :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      " |  of :class:`~torch.utils.data.DataLoader`.\n",
      " |  \n",
      " |  .. note::\n",
      " |    :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
      " |    sampler that yields integral indices.  To make it work with a map-style\n",
      " |    dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  __getitem__(self, index) -> +T_co\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  __parameters__ = (+T_co,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b29db082-64f2-4535-836b-f2db601d1f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m        \n",
       "\u001b[1;32mclass\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGeneric\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mT_co\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34mr\"\"\"An abstract class representing a :class:`Dataset`.\n",
       "\n",
       "    All datasets that represent a map from keys to data samples should subclass\n",
       "    it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
       "    data sample for a given key. Subclasses could also optionally overwrite\n",
       "    :meth:`__len__`, which is expected to return the size of the dataset by many\n",
       "    :class:`~torch.utils.data.Sampler` implementations and the default options\n",
       "    of :class:`~torch.utils.data.DataLoader`.\n",
       "\n",
       "    .. note::\n",
       "      :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
       "      sampler that yields integral indices.  To make it work with a map-style\n",
       "      dataset with non-integral indices/keys, a custom sampler must be provided.\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT_co\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Dataset[T_co]'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'ConcatDataset[T_co]'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mConcatDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# No `def __len__(self)` default?\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# See NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# in pytorch/torch/utils/data/sampler.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\tibeme_user\\anaconda3\\envs\\test1\\lib\\site-packages\\torch\\utils\\data\\dataset.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     IterableDataset, TensorDataset, ConcatDataset, Subset, MapDataPipe\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dataset??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63ca1e-82ed-45f6-b47c-7cb1c02aeef2",
   "metadata": {},
   "source": [
    "## 讀取自己的數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e7ad8d-692d-4543-87e9-af8a463cd5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        \"\"\"\n",
    "            Animal Dataset\n",
    "            param data_dir: str, 數據集所在路徑\n",
    "            param transform: torch.transform，數據預處理, 默認不進行處理\n",
    "            self.data_info: (圖片路徑, 標籤)的列表(全部圖片), [(), (), ...]\n",
    "        \"\"\"\n",
    "        self.data_info = self.get_img_info(data_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_img, label = self.data_info[index]\n",
    "        img = Image.open(path_img).convert('RGB')  # 圖片需轉RGB\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    # 返回所有圖片的路徑和標籤\n",
    "    @staticmethod\n",
    "    def get_img_info(data_dir):\n",
    "        data_info = list()\n",
    "        for root, dirs, _ in os.walk(data_dir):\n",
    "            if dirs:\n",
    "                for sub_dir in dirs:\n",
    "                    file_names = os.listdir(os.path.join(root, sub_dir))\n",
    "                    # 僅保留.jpg的檔案\n",
    "                    img_names = list(filter(lambda x: x.endswith('.jpg'), file_names))\n",
    "\n",
    "                    for img_name in img_names:\n",
    "                        path_img = os.path.join(root, sub_dir, img_name)\n",
    "                        label = sub_dir  # 0: ants, 1: bees\n",
    "                        data_info.append((path_img, int(label)))\n",
    "        return data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe8ef44-8d03-4335-bf6e-4dabad208d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(animal_train):  28\n",
      "label:  0\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "animal_train = Animal('./Data/hymenoptera_data/train', transform=train_transform)\n",
    "animal_test = Animal('./Data/hymenoptera_data/test', transform=test_transform)\n",
    "print('len(animal_train): ', len(animal_train))  # __len__\n",
    "img, label = animal_train[1]  # __getitem__\n",
    "print('label: ', label)\n",
    "print(type(img))\n",
    "# # 可視化\n",
    "# trans = transforms.ToPILImage()\n",
    "# img = trans(img)\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b49809e-fd98-406b-bd20-520539265773",
   "metadata": {},
   "source": [
    "## DataLoder\n",
    "### dataset: 繼承Dataset的數據集\n",
    "### batch_size: 一個Batch多少數據, 太大可能Gpu負荷不了\n",
    "### shuffle: 是否打亂(建議True)\n",
    "### drop_last: 除不盡的時候是否捨去\n",
    "### num_workers: 多進程, Windows下設置大於0有時候會報錯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c7d2c8c-708e-4af3-8cee-dce83f857c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 1, 0, 1])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([0, 0, 1, 0, 1, 0, 1, 1, 0, 0])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 1, 1])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 0, 0, 1])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 0])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 0, 1, 1])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 1])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 1])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 1])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([0, 0, 1, 1, 0, 1, 1, 1, 0, 0])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 1])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([0, 0, 1, 1, 1, 1, 1, 1, 0, 1])\n",
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "torch.Size([3, 3, 224, 224])\n",
      "tensor([0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# 切分BATCH_SIZE\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "animal_train = Animal('./Data/hymenoptera_data/train', transform=train_transform)\n",
    "animal_test = Animal('./Data/hymenoptera_data/test', transform=test_transform)\n",
    "train_loader = DataLoader(dataset=animal_train, batch_size=10, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(dataset=animal_test, batch_size=10, shuffle=True, drop_last=False)\n",
    "for epoch in range(1):\n",
    "    for data in test_loader:\n",
    "        imgs, targets = data\n",
    "        print(imgs.shape)  # 10張 3 * 224 * 224的圖片\n",
    "        print(targets)  # 10個 label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17721c76-d031-4756-ab4e-bc9f22ecccd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
