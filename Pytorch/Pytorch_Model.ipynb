{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8be8f9ce-a779-476c-84b0-7f4bd5a5863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.nn import Conv2d\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73684c89-c1c1-4e01-87e2-be0facc85583",
   "metadata": {},
   "source": [
    "# Gradient descent\n",
    "## Computation graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f186e7a8-6951-4e6a-a4d3-d3509ce4eb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c tensor(3., grad_fn=<AddBackward0>)\n",
      "d tensor(2., grad_fn=<AddBackward0>)\n",
      "e tensor(6., grad_fn=<MulBackward0>)\n",
      "<AddBackward0 object at 0x000001CA1FF92C10>\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(2.0, requires_grad=True) # we set requires_grad=True to let PyTorch know to keep the graph\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "c = a + b  # 雖沒設定 requires_grad=True, 但也有\n",
    "d = b + 1\n",
    "e = c * d\n",
    "print('c', c)\n",
    "print('d', d)\n",
    "print('e', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94745659-9296-467c-b589-6eb1e6531ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical f'(x): tensor([-2.], grad_fn=<MulBackward0>)\n",
      "PyTorch's f'(x): tensor([-2.])\n"
     ]
    }
   ],
   "source": [
    "def f(x):  # 方程式\n",
    "    return (x-2)**2\n",
    "\n",
    "def fp(x):  # 解析解\n",
    "    return 2*(x-2)\n",
    "\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "y = f(x)\n",
    "y.backward()  # 算微分\n",
    "\n",
    "print('Analytical f\\'(x):', fp(x))  \n",
    "print('PyTorch\\'s f\\'(x):', x.grad)  # 微分值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bda53ba7-760d-453f-a502-ebcd4967a991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical grad g(w) tensor([2.0000, 5.2832])\n",
      "PyTorch's grad g(w) tensor([2.0000, 5.2832])\n"
     ]
    }
   ],
   "source": [
    "def g(w):\n",
    "    return 2*w[0]*w[1] + w[1]*torch.cos(w[0])\n",
    "\n",
    "def grad_g(w):  # 解析解\n",
    "    return torch.tensor([2*w[1] - w[1]*torch.sin(w[0]), 2*w[0] + torch.cos(w[0])])\n",
    "\n",
    "w = torch.tensor([np.pi, 1], requires_grad=True)\n",
    "\n",
    "z = g(w)\n",
    "z.backward()  # 算微分  \n",
    "\n",
    "print('Analytical grad g(w)', grad_g(w))\n",
    "print('PyTorch\\'s grad g(w)', w.grad)  #微分值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edcde9f5-0adb-4356-be39-b2f1f1a03791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tx,\tf(x),\tf'(x),\tf'(x) pytorch\n",
      "0,\t5.000,\t9.000,\t6.000,\t6.000\n",
      "1,\t3.500,\t2.250,\t3.000,\t3.000\n",
      "2,\t2.750,\t0.562,\t1.500,\t1.500\n",
      "3,\t2.375,\t0.141,\t0.750,\t0.750\n",
      "4,\t2.188,\t0.035,\t0.375,\t0.375\n",
      "5,\t2.094,\t0.009,\t0.188,\t0.188\n",
      "6,\t2.047,\t0.002,\t0.094,\t0.094\n",
      "7,\t2.023,\t0.001,\t0.047,\t0.047\n",
      "8,\t2.012,\t0.000,\t0.023,\t0.023\n",
      "9,\t2.006,\t0.000,\t0.012,\t0.012\n",
      "10,\t2.003,\t0.000,\t0.006,\t0.006\n",
      "11,\t2.001,\t0.000,\t0.003,\t0.003\n",
      "12,\t2.001,\t0.000,\t0.001,\t0.001\n",
      "13,\t2.000,\t0.000,\t0.001,\t0.001\n",
      "14,\t2.000,\t0.000,\t0.000,\t0.000\n"
     ]
    }
   ],
   "source": [
    "def f(x):  # 方程式\n",
    "    return (x-2)**2\n",
    "\n",
    "def fp(x):  # 解析解\n",
    "    return 2*(x-2)\n",
    "\n",
    "x = torch.tensor([5.0], requires_grad=True)\n",
    "step_size = 0.25\n",
    "\n",
    "print('iter,\\tx,\\tf(x),\\tf\\'(x),\\tf\\'(x) pytorch')\n",
    "for i in range(15):\n",
    "    y = f(x)\n",
    "    y.backward() # compute the gradient\n",
    "    \n",
    "    print('{},\\t{:.3f},\\t{:.3f},\\t{:.3f},\\t{:.3f}'.format(i, x.item(), f(x).item(), fp(x).item(), x.grad.item()))\n",
    "    \n",
    "    x.data = x.data - step_size * x.grad # perform a GD update step\n",
    "    \n",
    "    # We need to zero the grad variable since the backward()\n",
    "    # call accumulates the gradients in .grad instead of overwriting.\n",
    "    # The detach_() is for efficiency. You do not need to worry too much about it.\n",
    "    x.grad.detach_()\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b4ad1-01d2-4e5a-a072-b0054f477122",
   "metadata": {},
   "source": [
    "# Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20204f1c-0ac9-441d-b7a7-9b96cdc91de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_tensor tensor([-1.,  1.,  0.])\n",
      "activated tensor([0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "activation_fn = nn.ReLU()  # we instantiate an instance of the ReLU module\n",
    "example_tensor = torch.tensor([-1.0, 1.0, 0.0])\n",
    "activated = activation_fn(example_tensor)\n",
    "print('example_tensor', example_tensor)\n",
    "print('activated', activated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd5659c-9c35-4a71-bfd5-12c48bc27b07",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a41a5888-737a-45ce-b9b7-8a3ee959fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6667)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "input = torch.tensor([0., 0, 0])  # dtype: torch.float32\n",
    "target = torch.tensor([1, 0, -1])  # torch.int64\n",
    "loss = loss_fn(input, target)\n",
    "print(loss)  # (1 + 0 + 1) / 3 = 0.6667"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4a7bbc-d34c-449c-931e-d8050132fa09",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a05f44ae-5c1a-4112-9573-9290564969b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params before: Parameter containing:\n",
      "tensor([[0.6623]], requires_grad=True)\n",
      "model params after: Parameter containing:\n",
      "tensor([[0.6925]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# create a simple model\n",
    "model = nn.Linear(1, 1)\n",
    "\n",
    "# create a simple dataset\n",
    "X_simple = torch.tensor([[1.]])\n",
    "y_simple = torch.tensor([[2.]])\n",
    "\n",
    "# create our optimizer\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "\n",
    "y_hat = model(X_simple)\n",
    "print('model params before:', model.weight)\n",
    "loss = mse_loss_fn(y_hat, y_simple)\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "print('model params after:', model.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0205c91d-e1dc-4b02-8fc3-e6627f3fb70b",
   "metadata": {},
   "source": [
    "# torch.nn\n",
    "## 取得Module的weght和bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd2a7dc-a2c0-4ca4-af1e-d0ff339c45cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: Parameter containing:\n",
      "tensor([[-0.1211,  0.4893,  0.0330],\n",
      "        [-0.1761, -0.1207,  0.1824],\n",
      "        [-0.3230,  0.4867,  0.4097],\n",
      "        [-0.5031, -0.3502,  0.5532]], requires_grad=True)\n",
      "b: Parameter containing:\n",
      "tensor([ 0.1155, -0.1199,  0.1164, -0.3833], requires_grad=True)\n",
      "example_tensor torch.Size([2, 3])\n",
      "transormed torch.Size([2, 4])\n",
      "\n",
      "We can see that the weights exist in the background\n",
      "\n",
      "W: Parameter containing:\n",
      "tensor([[-0.1211,  0.4893,  0.0330],\n",
      "        [-0.1761, -0.1207,  0.1824],\n",
      "        [-0.3230,  0.4867,  0.4097],\n",
      "        [-0.5031, -0.3502,  0.5532]], requires_grad=True)\n",
      "b: Parameter containing:\n",
      "tensor([ 0.1155, -0.1199,  0.1164, -0.3833], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "d_in = 3\n",
    "d_out = 4\n",
    "linear_module = nn.Linear(d_in, d_out)\n",
    "print('W:', linear_module.weight)\n",
    "print('b:', linear_module.bias)\n",
    "example_tensor = torch.tensor([[1.,2,3], [4,5,6]])\n",
    "# applys a linear transformation to the data\n",
    "transformed = linear_module(example_tensor)\n",
    "print('example_tensor', example_tensor.shape)\n",
    "print('transormed', transformed.shape)\n",
    "print()\n",
    "print('We can see that the weights exist in the background\\n')\n",
    "print('W:', linear_module.weight)\n",
    "print('b:', linear_module.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9213b2c-0a37-4644-81e0-f632399fd9ef",
   "metadata": {},
   "source": [
    "## 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1f93c71-3278-4549-9974-f3d8c642a7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hank()\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "class Hank(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 定義屬性\n",
    "\n",
    "    def forward(self, input):\n",
    "        # 調用該類別會使用forward\n",
    "        output = input + 1\n",
    "        return output\n",
    "\n",
    "\n",
    "hank = Hank()\n",
    "x = torch.tensor(1.0)\n",
    "output = hank(x)\n",
    "print(hank)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e14feea-8b22-4fb2-a71a-a41953fa2ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([[1, 2, 0, 3, 1],\n",
    "                      [0, 1, 2, 3, 1],\n",
    "                      [1, 2, 1, 0, 0],\n",
    "                      [5, 2, 3, 1, 1],\n",
    "                      [2, 1, 0, 1, 1]])\n",
    "\n",
    "kernel = torch.tensor([[1, 2, 1],\n",
    "                       [0, 1, 0],\n",
    "                       [2, 1, 0]])\n",
    "\n",
    "input = torch.reshape(input, (1, 1, 5, 5))\n",
    "kernel = torch.reshape(kernel, (1, 1, 3, 3))\n",
    "\n",
    "print(input.shape)\n",
    "print(kernel.shape)\n",
    "\n",
    "# input –\n",
    "# input tensor of shape (\\text{minibatch} , \\text{in\\_channels} , iH , iW)(minibatch,in_channels,iH,iW)\n",
    "output = F.conv2d(input, kernel, stride=1)\n",
    "print(output)\n",
    "\n",
    "output2 = F.conv2d(input, kernel, stride=2)\n",
    "print(output2)\n",
    "\n",
    "output3 = F.conv2d(input, kernel, stride=1, padding=1)\n",
    "print(output3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0814af07-5cbb-401f-ac6f-f035e95cead0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Hank(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    \"Data/dataset\", train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "# 圖片大小: torch.Size([3, 32, 32])\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "\n",
    "class Hank(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Hank, self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "hank = Hank()\n",
    "print(hank)\n",
    "for data in dataloader:\n",
    "    imgs, targets = data\n",
    "    output = hank(imgs)\n",
    "    # print(imgs.shape)  # torch.Size([64, 3, 32, 32])  Batchsize C H W\n",
    "    # print(output.shape)  # torch.Size([64, 6, 30, 30])\n",
    "    output = torch.reshape(output, (-1, 3, 30, 30))  # torch.Size([64, 6, 30, 30])  -> [xxx, 3, 30, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28b3cb-b297-4ad4-9664-53fd0a5b3161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e790ad-2902-4f9c-8a8d-a0d8b9658920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
